---
{
  "title": "Migrating from MapRerankDocumentsChain",
  "source_url": "https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain/",
  "fetched_at": "2025-08-15T13:52:00.720951+00:00"
}
---

# Migrating from MapRerankDocumentsChain

import
operator
from
typing
import
Annotated
,
List
,
TypedDict
from
langchain_core
.
prompts
import
ChatPromptTemplate
from
langchain_openai
import
ChatOpenAI
from
langgraph
.
constants
import
Send
from
langgraph
.
graph
import
END
,
START
,
StateGraph
class
AnswerWithScore
(
TypedDict
)
:
answer
:
str
score
:
Annotated
[
int
,
.
.
.
,
"Score from 1-10."
]
llm
=
ChatOpenAI
(
model
=
"gpt-4o-mini"
,
temperature
=
0
)
prompt_template
=
"What color are Bob's eyes?\n\nContext: {context}"
prompt
=
ChatPromptTemplate
.
from_template
(
prompt_template
)
map_chain
=
prompt
|
llm
.
with_structured_output
(
AnswerWithScore
)
class
State
(
TypedDict
)
:
contents
:
List
[
str
]
answers_with_scores
:
Annotated
[
list
,
operator
.
add
]
answer
:
str
class
MapState
(
TypedDict
)
:
content
:
str
def
map_analyses
(
state
:
State
)
:
return
[
Send
(
"generate_analysis"
,
{
"content"
:
content
}
)
for
content
in
state
[
"contents"
]
]
async
def
generate_analysis
(
state
:
MapState
)
:
response
=
await
map_chain
.
ainvoke
(
state
[
"content"
]
)
return
{
"answers_with_scores"
:
[
response
]
}
def
pick_top_ranked
(
state
:
State
)
:
ranked_answers
=
sorted
(
state
[
"answers_with_scores"
]
,
key
=
lambda
x
:
-
int
(
x
[
"score"
]
)
)
return
{
"answer"
:
ranked_answers
[
0
]
}
graph
=
StateGraph
(
State
)
graph
.
add_node
(
"generate_analysis"
,
generate_analysis
)
graph
.
add_node
(
"pick_top_ranked"
,
pick_top_ranked
)
graph
.
add_conditional_edges
(
START
,
map_analyses
,
[
"generate_analysis"
]
)
graph
.
add_edge
(
"generate_analysis"
,
"pick_top_ranked"
)
graph
.
add_edge
(
"pick_top_ranked"
,
END
)
app
=
graph
.
compile
(
)
