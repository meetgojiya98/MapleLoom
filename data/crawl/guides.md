---
{
  "title": "Guides",
  "source_url": "https://langchain-ai.github.io/langgraph/guides/",
  "fetched_at": "2025-08-15T13:52:14.890300+00:00"
}
---

# Guides

Guides
The pages in this section provide a conceptual overview and how-tos for the following topics:
Agent development
Overview
: Use prebuilt components to build an agent.
Run an agent
: Run an agent by providing input, interpreting output, enabling streaming, and controlling execution limits.
LangGraph APIs
Graph API
: Use the Graph API to define workflows using a graph paradigm.
Functional API
: Use Functional API to build workflows using a functional paradigm without thinking about the graph structure.
Runtime
: Pregel implements LangGraph's runtime, managing the execution of LangGraph applications.
Core capabilities
These capabilities are available in both LangGraph OSS and the LangGraph Platform.
Streaming
: Stream outputs from a LangGraph graph.
Persistence
: Persist the state of a LangGraph graph.
Durable execution
: Save progress at key points in the graph execution.
Memory
: Remember information about previous interactions.
Context
: Pass outside data to a LangGraph graph to provide context for the graph execution.
Models
: Integrate various LLMs into your LangGraph application.
Tools
: Interface directly with external systems.
Human-in-the-loop
: Pause a graph and wait for human input at any point in a workflow.
Time travel
: Travel back in time to a specific point in the execution of a LangGraph graph.
Subgraphs
: Build modular graphs.
Multi-agent
: Break down a complex workflow into multiple agents.
MCP
: Use MCP servers in a LangGraph graph.
Evaluation
: Use LangSmith to evaluate your graph's performance.
