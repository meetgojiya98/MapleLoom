---
{
  "title": "How to use callbacks in async environments",
  "source_url": "https://python.langchain.com/docs/how_to/callbacks_async/",
  "fetched_at": "2025-08-15T13:49:32.389371+00:00"
}
---

# How to use callbacks in async environments

import
asyncio
from
typing
import
Any
,
Dict
,
List
from
langchain_anthropic
import
ChatAnthropic
from
langchain_core
.
callbacks
import
AsyncCallbackHandler
,
BaseCallbackHandler
from
langchain_core
.
messages
import
HumanMessage
from
langchain_core
.
outputs
import
LLMResult
class
MyCustomSyncHandler
(
BaseCallbackHandler
)
:
def
on_llm_new_token
(
self
,
token
:
str
,
**
kwargs
)
-
>
None
:
print
(
f"Sync handler being called in a `thread_pool_executor`: token:
{
token
}
"
)
class
MyCustomAsyncHandler
(
AsyncCallbackHandler
)
:
"""Async callback handler that can be used to handle callbacks from langchain."""
async
def
on_llm_start
(
self
,
serialized
:
Dict
[
str
,
Any
]
,
prompts
:
List
[
str
]
,
**
kwargs
:
Any
)
-
>
None
:
"""Run when chain starts running."""
print
(
"zzzz...."
)
await
asyncio
.
sleep
(
0.3
)
class_name
=
serialized
[
"name"
]
print
(
"Hi! I just woke up. Your llm is starting"
)
async
def
on_llm_end
(
self
,
response
:
LLMResult
,
**
kwargs
:
Any
)
-
>
None
:
"""Run when chain ends running."""
print
(
"zzzz...."
)
await
asyncio
.
sleep
(
0.3
)
print
(
"Hi! I just woke up. Your llm is ending"
)
chat
=
ChatAnthropic
(
model
=
"claude-3-7-sonnet-20250219"
,
max_tokens
=
25
,
streaming
=
True
,
callbacks
=
[
MyCustomSyncHandler
(
)
,
MyCustomAsyncHandler
(
)
]
,
)
await
chat
.
agenerate
(
[
[
HumanMessage
(
content
=
"Tell me a joke"
)
]
]
)
